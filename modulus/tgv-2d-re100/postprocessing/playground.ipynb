{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import pathlib\n",
    "import numpy\n",
    "import scipy.interpolate\n",
    "import ipywidgets\n",
    "import pandas\n",
    "from h5py import File as h5open\n",
    "from cycler import cycler\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors\n",
    "from matplotlib import ticker\n",
    "from matplotlib.legend_handler import HandlerTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find helpers and locate workdir\n",
    "for parent in [pathlib.Path.cwd()] + list(pathlib.Path.cwd().parents):\n",
    "    if parent.joinpath(\"modulus\").is_dir():\n",
    "        projdir = parent\n",
    "        sys.path.insert(0, str(projdir.joinpath(\"modulus\")))\n",
    "        from helpers.utils import read_tensorboard_data  # pylint: disable=import-error\n",
    "        from helpers.lr_simulator import widget as lr_widget\n",
    "        from helpers.utils import log_parser  # pylint: disable=import-error\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"Couldn't find module `helpers`.\")\n",
    "\n",
    "# point workdir to the correct folder\n",
    "workdir = projdir.joinpath(\"modulus\", \"tgv-2d-re100\")\n",
    "petibmdir = projdir.joinpath(\"petibm\", \"taylor-green-vortex-2d-re100\")\n",
    "figdir = workdir.joinpath(\"figures\")\n",
    "figdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unified figure style\n",
    "pyplot.style.use(projdir.joinpath(\"resources\", \"figstyle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "nls = [1, 2, 3]\n",
    "nns = [16, 32, 64, 128, 256]\n",
    "nbss = [1024, 2048, 4096, 8192, 16384, 32768, 65536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_base_case():\n",
    "    \"\"\"Plot figures for the case performed the best for averaged spatial-temporal error.\n",
    "    \"\"\"\n",
    "    bestl2norm = float(\"inf\")\n",
    "    best = None\n",
    "    for nl, nn, nbs in itertools.product(nls, nns, nbss):\n",
    "        with h5open(workdir.joinpath(\"outputs\", \"base-cases\", f\"nl{nl}-nn{nn}-npts{nbs}-raw.h5\"), \"r\") as h5file:\n",
    "            err = float(h5file[f\"sterrs/u/l2norm\"][...])\n",
    "        \n",
    "        if err < bestl2norm:\n",
    "            bestl2norm = err\n",
    "            best = (nl, nn, nbs)\n",
    "    return best, bestl2norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_base_case():\n",
    "    \"\"\"Plot figures for the case performed the best for averaged spatial-temporal error.\n",
    "    \"\"\"\n",
    "    worstl2norm = - float(\"inf\")\n",
    "    worst = None\n",
    "    for nl, nn, nbs in itertools.product(nls, nns, nbss):\n",
    "        with h5open(workdir.joinpath(\"outputs\", \"base-cases\", f\"nl{nl}-nn{nn}-npts{nbs}-raw.h5\"), \"r\") as h5file:\n",
    "            err = float(h5file[f\"sterrs/u/l2norm\"][...])\n",
    "        \n",
    "        if err > worstl2norm:\n",
    "            worstl2norm = err\n",
    "            worst = (nl, nn, nbs)\n",
    "    return worst, worstl2norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"raw, (best case, err): {get_best_base_case()}\")\n",
    "print(f\"raw, (worst case, err): {get_worst_base_case()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_base_case_training_history(workdir, figdir, nl, nn, nbs, ws):\n",
    "    \"\"\"Plot figures related to training loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # fixed cycling kwargs\n",
    "    kwargs = \\\n",
    "        cycler(\"color\", pyplot.cm.tab10.colors[:3]) + \\\n",
    "        cycler(\"label\", [\"Raw data\", \"Moving averaged\", \"Moving minimum\"]) + \\\n",
    "        cycler(\"linewidth\", [0.3, 1.5, 1.5])\n",
    "    kwargs = kwargs()\n",
    "\n",
    "    kwr = next(kwargs)\n",
    "    kwa = next(kwargs)\n",
    "    kwm = next(kwargs)\n",
    "\n",
    "    data = log_parser(workdir.joinpath(f\"nl{nl}-nn{nn}-npts{nbs}\"))\n",
    "\n",
    "    # plot according to optimizer type\n",
    "    fig, ax = pyplot.subplots(1, 1, sharex=False, sharey=False, figsize=(8, 4))\n",
    "    fig.suptitle(rf\"2D TGV, $Re=100$, $(N_l, N_n, N_{{bs}})=({nl}, {nn}, {nbs})$\")\n",
    "    \n",
    "    # against steps\n",
    "    ax.set_title(\"Aggregated loss v.s. iterations\")\n",
    "    ax.semilogy(data.index, data.loss, alpha=0.3, **kwr)\n",
    "    ax.semilogy(data.index, data.loss.rolling(window=ws).mean(), **kwa)\n",
    "    ax.semilogy(data.index, data.loss.rolling(window=ws).min(), **kwm)\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Aggregated loss\")\n",
    "    ax.legend(loc=0)\n",
    "\n",
    "    # time axis\n",
    "    axtime = ax.twiny()\n",
    "    axtime.spines[\"bottom\"].set_position((\"axes\", -0.3))\n",
    "    axtime.spines[\"bottom\"].set_visible(True)\n",
    "    axtime.xaxis.set_label_position(\"bottom\")\n",
    "    axtime.xaxis.set_ticks_position(\"bottom\")\n",
    "    axtime.set_xlabel(\"Run time (hours)\")\n",
    "    axtime.set_xlim(data.loc[0, \"time elapsed\"], data.iloc[-1][\"time elapsed\"])\n",
    "    axtime.get_xaxis().set_ticks_position(\"bottom\")\n",
    "\n",
    "    # save\n",
    "    figdir.joinpath(\"training-hist\").mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(figdir.joinpath(\"training-hist\", f\"nl{nl}-nn{nn}-npts{nbs}.png\"))\n",
    "    # pyplot.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot case training history\n",
    "option1 = ipywidgets.Dropdown(options=nls, value=3)\n",
    "option2 = ipywidgets.Dropdown(options=nns, value=256)\n",
    "option3 = ipywidgets.Dropdown(options=nbss, value=1024)\n",
    "option4 = ipywidgets.IntSlider(value=10, min=1, max=200, step=2, orientation=\"horizontal\") \n",
    "canvas = ipywidgets.interactive_output(\n",
    "    plot_base_case_training_history,\n",
    "    {\n",
    "        \"workdir\": ipywidgets.fixed(workdir.joinpath(\"base-cases\")),\n",
    "        \"figdir\": ipywidgets.fixed(figdir.joinpath(\"base-cases\")),\n",
    "        \"nl\": option1, \"nn\": option2, \"nbs\": option3, \"ws\": option4,\n",
    "    }\n",
    ")\n",
    "\n",
    "out = ipywidgets.VBox([option1, option2, option3, option4, canvas])\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_base_case_contour(nl, nn, nbs, time, workdir, figdir):\n",
    "    \"\"\"Plot figures for the case performed the best at t=40.\n",
    "    \"\"\"\n",
    "\n",
    "    with h5open(workdir.joinpath(f\"nl{nl}-nn{nn}-npts{nbs}-raw.h5\"), \"r\") as h5file:\n",
    "        coords = (h5file[\"field/x\"][...], h5file[\"field/y\"][...])\n",
    "\n",
    "        vals = {\n",
    "            r\"$u$\": h5file[f\"field/{time}/u\"][...],\n",
    "            r\"$v$\": h5file[f\"field/{time}/v\"][...],\n",
    "            r\"$p$\": h5file[f\"field/{time}/p\"][...],\n",
    "            r\"$\\omega_z$\": h5file[f\"field/{time}/vorticity_z\"][...],\n",
    "        }\n",
    "\n",
    "        errs = {\n",
    "            r\"$u$\": h5file[f\"field/{time}/err-u\"][...],\n",
    "            r\"$v$\": h5file[f\"field/{time}/err-v\"][...],\n",
    "            r\"$p$\": h5file[f\"field/{time}/err-p\"][...],\n",
    "            r\"$\\omega_z$\": h5file[f\"field/{time}/err-vorticity_z\"][...],\n",
    "        }\n",
    "\n",
    "    # re-cal. the pressure w/ the mean from analytical soln. as it is assumed to have a constant shift\n",
    "    ptrue = numpy.exp(-4.*0.01*float(time)) * (numpy.cos(2.*coords[0]) + numpy.cos(2.*coords[1])) / 4.\n",
    "    vals[r\"$p$\"] = vals[r\"$p$\"] - vals[r\"$p$\"].mean()\n",
    "    errs[r\"$p$\"] = abs(vals[r\"$p$\"] - ptrue)\n",
    "\n",
    "    fig, axs = pyplot.subplots(4, 2, sharex=True, sharey=True, figsize=(8.5, 13))\n",
    "\n",
    "    fig.suptitle(\n",
    "        rf\"Flow and errors, TGV 2D@$t={float(time)}$, $Re=100$, \"+\"\\n\" +\n",
    "        rf\"$(N_l, N_n, N_{{bs}})=({nl}, {nn}, {nbs})$\"\n",
    "    )\n",
    "\n",
    "    for i, field in enumerate([r\"$u$\", r\"$v$\", r\"$p$\", r\"$\\omega_z$\"]):\n",
    "        # field values\n",
    "        ct = axs[i, 0].contourf(*coords, vals[field], 16)\n",
    "        axs[i, 0].set_aspect(\"equal\")\n",
    "        axs[i, 0].set_title(field)\n",
    "        fig.colorbar(ct, ax=axs[i, 0])\n",
    "\n",
    "        # errors\n",
    "        ct = axs[i, 1].contourf(\n",
    "            *coords, errs[field], 16,\n",
    "            norm=colors.LogNorm(vmin=errs[field].min(), vmax=errs[field].max())\n",
    "        )\n",
    "        axs[i, 1].set_aspect(\"equal\")\n",
    "        axs[i, 1].set_title(f\"Absolute error, {field}\")\n",
    "        fmt = ticker.LogFormatter()                                                                                     \n",
    "        cbar = fig.colorbar(ct, ax=axs[i, 1], format=fmt)\n",
    "    \n",
    "    axs[0, 0].set_ylabel(r\"$y$\")\n",
    "    axs[1, 0].set_ylabel(r\"$y$\")\n",
    "    axs[2, 0].set_ylabel(r\"$y$\")\n",
    "    axs[3, 0].set_ylabel(r\"$y$\")\n",
    "    axs[3, 0].set_xlabel(r\"$x$\")\n",
    "    axs[3, 1].set_xlabel(r\"$x$\")\n",
    "\n",
    "    figdir.joinpath(\"contours\").mkdir(parents=True, exist_ok=True)\n",
    "    pyplot.savefig(figdir.joinpath(\"contours\", f\"nl{nl}-nn{nn}-npts{nbs}-t{time}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot contours for cases\n",
    "option1 = ipywidgets.Dropdown(options=nls, value=3)\n",
    "option2 = ipywidgets.Dropdown(options=nns, value=256)\n",
    "option3 = ipywidgets.Dropdown(options=nbss, value=1024)\n",
    "option4 = ipywidgets.Dropdown(options=[\"0.0\", \"40.0\", \"80.0\"], value=\"40.0\")\n",
    "canvas = ipywidgets.interactive_output(\n",
    "    plot_base_case_contour,\n",
    "    {\n",
    "        \"nl\": option1, \"nn\": option2, \"nbs\": option3, \"time\": option4,\n",
    "        \"workdir\": ipywidgets.fixed(workdir.joinpath(\"outputs\", \"base-cases\")),\n",
    "        \"figdir\": ipywidgets.fixed(figdir.joinpath(\"base-cases\"))\n",
    "    }\n",
    ")\n",
    "display(ipywidgets.VBox([option1, option2, option3, option4, canvas]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_err_arch_boxplot(field, workdir, figdir):\n",
    "    \"\"\"plot_err_arch_boxplot\n",
    "    \"\"\"\n",
    "    data = {\"nl\": [], \"nn\": [], \"nbs\": [], \"l2norm\": []}\n",
    "    for nl, nn, nbs in itertools.product(nls, nns, nbss):\n",
    "        data[\"nl\"].append(nl)\n",
    "        data[\"nn\"].append(nn)\n",
    "        data[\"nbs\"].append(nbs)\n",
    "        with h5open(workdir.joinpath(f\"nl{nl}-nn{nn}-npts{nbs}-raw.h5\"), \"r\") as h5file:\n",
    "            data[\"l2norm\"].append(float(h5file[f\"sterrs/{field}/l2norm\"][...]))\n",
    "\n",
    "    data = pandas.DataFrame(data)\n",
    "    data = data.pivot(index=\"nbs\", columns=[\"nl\", \"nn\"], values=\"l2norm\")\n",
    "    data = data[data.mean().sort_values(ascending=False).index]\n",
    "\n",
    "    fig, ax = pyplot.subplots(1, 1)\n",
    "    fig.suptitle(r\"Error distribution across network architectures\")\n",
    "\n",
    "    ax.boxplot(\n",
    "        data.values, labels=data.columns, showmeans=True,\n",
    "        meanprops={\"marker\": \".\", \"mfc\": \"k\", \"mec\": \"k\"},\n",
    "        medianprops={\"ls\": \"none\"},\n",
    "    )\n",
    "    ax.tick_params(axis=\"x\", labelrotation=45)\n",
    "    ax.set_xlabel(r\"$(N_l, N_n)$\")\n",
    "    ax.set_ylabel(rf\"$l_2$-norm of ${field}$\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    figdir.joinpath(\"err-vs-arch\").mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(figdir.joinpath(\"err-vs-arch\", f\"err-arch-boxplot-{field}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error vs. network arch\n",
    "option1 = ipywidgets.Dropdown(options=[\"u\", \"v\"], value=\"u\", description=\"Velocity\")\n",
    "canvas = ipywidgets.interactive_output(\n",
    "    plot_err_arch_boxplot,\n",
    "    {\n",
    "        \"field\": option1,\n",
    "        \"workdir\": ipywidgets.fixed(workdir.joinpath(\"outputs\", \"base-cases\")),\n",
    "        \"figdir\": ipywidgets.fixed(figdir.joinpath(\"outputs\", \"base-cases\"))\n",
    "    }\n",
    ")\n",
    "out = ipywidgets.HBox([canvas, option1])\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(lr_widget())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('modulus')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88d2f06bb247d746ec823ea9336c693995af707d84c221c7086d89f854987291"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
